# -*- coding: utf-8 -*-
"""Spark_Installation_on_Colab.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QT15dDrJMoSd9NXYpj5ZQubLZ_iqnw52

# Colab is a Linux environment. 

# You can execute Linux commands from Colab notebook with a "!" prefix

## Install JDK
"""

!apt-get install openjdk-8-jdk-headless -qq > /dev/null

"""## Get Spark installer (Check the path on Spark.org)"""

!wget -q http://apachemirror.wuchna.com/spark/spark-2.4.3/spark-2.4.3-bin-hadoop2.7.tgz

"""## Check if the file is copied"""

!ls

"""## Untar the Spark installer"""

!tar -xvf spark-2.4.3-bin-hadoop2.7.tgz

"""## Check the spark folder after untar"""

!ls

"""## Install findspark - a Python library to find Spark"""

!pip install -q findspark

"""## Set environment variables
Set Java and Spark Home based on location where they are stored
"""

import os
os.environ["JAVA_HOME"] = "/usr/lib/jvm/java-8-openjdk-amd64"
os.environ["SPARK_HOME"] = "/content/spark-2.4.3-bin-hadoop2.7"

"""## Create a local Spark Session"""

import findspark
findspark.init()
from pyspark.sql import SparkSession
spark = SparkSession.builder.master("local[*]").getOrCreate()

"""## Test Installation"""

df = spark.createDataFrame([{"Google": "Colab","Spark": "Scala"} ,{"Google": "Dataproc","Spark":"Python"}])
df.show()

